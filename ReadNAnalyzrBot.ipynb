{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078fc810",
   "metadata": {},
   "source": [
    "# ReadNAnalyzrBot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42273a0",
   "metadata": {},
   "source": [
    "## Installing and Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a98487fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Instal the required modules:\n",
    "#pip install textblob\n",
    "#pip install beautifulsoup4\n",
    "#pip install nltk\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import chardet\n",
    "import string\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#REPLACE THE LOCATION OF THE FOLLOWING DIRECTORIES IN YOUR SYSTEM:\n",
    "input_file_location = r'D:\\DATA ANALYST PLAYGROUND\\Blackcoffer\\Input 1.xlsx'\n",
    "extracted_txt_folder_path = r'D:\\DATA ANALYST PLAYGROUND\\Blackcoffer\\Extracted Text files'\n",
    "stop_words_folder = r'D:\\DATA ANALYST PLAYGROUND\\Blackcoffer\\StopWords'\n",
    "positive_words_loc = r'D:\\DATA ANALYST PLAYGROUND\\Blackcoffer\\MasterDictionary\\positive-words.txt'\n",
    "negative_words_loc = r'D:\\DATA ANALYST PLAYGROUND\\Blackcoffer\\MasterDictionary/negative-words.txt'\n",
    "output_excel_path = r'D:\\DATA ANALYST PLAYGROUND\\Blackcoffer\\Output Data Structure.xlsx'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ecd864",
   "metadata": {},
   "source": [
    "## Load input Excel file that contains URL of the sights you need to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6102fbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TestURL0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TestURL0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TestURL0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TestURL0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TestURL0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>TestURL0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>TestURL0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>TestURL0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>TestURL0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>TestURL0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         URL_ID                                                URL\n",
       "0   TestURL0001  https://insights.blackcoffer.com/rising-it-cit...\n",
       "1   TestURL0002  https://insights.blackcoffer.com/rising-it-cit...\n",
       "2   TestURL0003  https://insights.blackcoffer.com/internet-dema...\n",
       "3   TestURL0004  https://insights.blackcoffer.com/rise-of-cyber...\n",
       "4   TestURL0005  https://insights.blackcoffer.com/ott-platform-...\n",
       "..          ...                                                ...\n",
       "95  TestURL0096  https://insights.blackcoffer.com/what-is-the-r...\n",
       "96  TestURL0097  https://insights.blackcoffer.com/impact-of-cov...\n",
       "97  TestURL0098  https://insights.blackcoffer.com/contribution-...\n",
       "98  TestURL0099  https://insights.blackcoffer.com/how-covid-19-...\n",
       "99  TestURL0100  https://insights.blackcoffer.com/how-will-covi...\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input_file_location = r'D:\\DATA ANALYST PLAYGROUND\\Blackcoffer\\Input.xlsx'\n",
    "input_file = pd.read_excel(input_file_location)\n",
    "input_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141cc016",
   "metadata": {},
   "source": [
    "## Extracting texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dab6ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_article_text(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Extracting article title\n",
    "    title_element_1 = soup.find('h1', class_='entry-title')\n",
    "    title_element_2 = soup.find('h1', class_='tdb-title-text')\n",
    "\n",
    "    # Use the title from the first found element (non-empty)\n",
    "    title = title_element_1.text.strip() if title_element_1 else title_element_2.text.strip() if title_element_2 else \"\"\n",
    "    \n",
    "    # Extracting article text \n",
    "    article_text_element_1 = soup.find(class_=\"td-post-content tagdiv-type\")\n",
    "\n",
    "    if article_text_element_1:\n",
    "        # Ignore text inside \"wp-block-preformatted\" class\n",
    "        preformatted_elements = article_text_element_1.find_all(class_=\"wp-block-preformatted\")\n",
    "        for preformatted_element in preformatted_elements:\n",
    "            preformatted_element.decompose()  # Remove the element and its content\n",
    "        \n",
    "        # Extract text after removing \"wp-block-preformatted\" elements\n",
    "        article_text = article_text_element_1.text.strip()\n",
    "    else:\n",
    "        # If not found, try to find text inside <p>, <li>, and <u> tags in \"tdb-block-inner td-fix-index\"\n",
    "        tdb_block_inner_elements = soup.find_all(class_=\"tdb-block-inner td-fix-index\")\n",
    "        combined_texts = []\n",
    "\n",
    "        for tdb_block_inner in tdb_block_inner_elements:\n",
    "            # Extract text from <p>, <li>, and <u> tags\n",
    "            p_elements = tdb_block_inner.find_all(['p', 'li', 'u'])\n",
    "            combined_texts.extend([element.text.strip() for element in p_elements if element.text.strip()])\n",
    "\n",
    "        article_text = ' '.join(combined_texts)\n",
    "\n",
    "    article_text = re.sub(r'\\n', '', article_text)\n",
    "\n",
    "    \n",
    "    return title, article_text\n",
    "\n",
    "\n",
    "\n",
    "#\"td-post-content tagdiv-type\"\n",
    "#\"tdb-block-inner td-fix-index\"\n",
    "#\"tdb-title-text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0a2fa70e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('How will COVID-19 affect the world of work?',\n",
       " 'As business close to help prevent transmission of COVID-19, financial concerns and job losses are one of the first human impacts of the virus; Not knowing how this pandemic will play out also affects our economic, physical and mental well-being; Despite this fear, businesses and communities in many regions have shown a more altruistic response in the face of crisis – actions which could help countries preparing for COVID-19. COVID-19 is in decline in China. There are now more new cases every day in Europe than there were in China at the epidemic’s peak and Italy has surpassed it as the country with the most deaths from the virus It took 67 days to reach the first 100,000 confirmed cases worldwide, 11 days for this to increase to 200,000and just four to reach 300,000 confirmed cases – a figure now exceeded. In recent weeks, we have seen the significant economic impact of the coronavirus on financial markets and vulnerable industries such as manufacturing, tourism, hospitality and travel.\\xa0Travel and tourism account for 10% of the global GDP and 50 million jobs are at risk worldwide. Global tourism, travel and hospitality companies closing down affects SMEs globally. This, in turn, affects many people, typically the least well-paid and those self-employed or working in informal environments in the gig economy or in part-time work with zero-hours contracts. Some governments have announced economic measures to safeguard jobs, guarantee wages and support the self-employed, but there is a lack of clarity in many countries about how these measures will be implemented and how people will manage a loss of income in the short-term. Behind these statistics lie the human costs of the pandemic, from the deaths of friends and family to the physical effects of infection and the mental trauma and fear faced by almost everyone. Not knowing how this pandemic will play out affects our economic, physical and mental well-being against a backdrop of a world that, for many, is increasingly anxious, unhappy and lonely. Fear of the unknown can often lead to feelings of panic, for example when people feel they are being denied life-saving protection or treatment or that they may run out of necessities, which can lead to panic buying.Psychological stress is often related to a sense of a lack of control in the face of uncertainty. In all cases, lack of information or the wrong information, either provided inadvertently or maliciously, can amplify the effects. There is a huge amount of misleading information circulating online about COVID-19, from fake medical information to speculation about government responses. People are susceptible to social media posts from an apparently trustworthy source, often referred to as an “Uncle with a Masters”-post, possibly amplified and spread by “copypasta” posts, which share information by copying and pasting and make each new post look like an original source, as opposed to posts that are “liked” or “shared” or “retweeted”. Sadly, criminals and hackers are also exploiting this situation and there has been a significant rise in Coronavirus-themed malicious websites, with more than 16,000 new coronavirus-related domains registered since January 2020. Hackers are selling malware and hacking tools through COVID-19 discount codes on the darknet,many of which are aimed at accessing corporate data from home-workers’ laptops, which may not be as secure as outside an office environment. Social distancing and lockdowns have also prompted altruistic behaviors, in part because of the sense that “we’re all in this together”. Many people report being bored or concerned about putting on weight;\\xa0others have discovered a slower pace of life and by not going out and socializing have found more time for family, others, and even their pets. The downside of self-isolation or social lockdown are symptoms of traumatic stress, confusion and anger, all of which are exacerbated by fear of infection, having limited access to supplies of necessities, inadequate information or the experience of economic loss or stigma. This stress and anxiety can lead to increased alcohol consumption, as well as an increase in domestic and family violence.In Jingzhou, a town near Wuhan in Hubei province, reports of domestic violence during the lockdown in February 2020 were more than triple the number reported in February 2019. Health measures must be the first priority for governments, business and society. It is important for businesses to show solidarity and work together to protect staff, local communities and customers, as well as keeping supply chains, manufacturing and logistics working.According to research, “my employer” is more trusted than the government or media. Daily updates on a company website with input from scientists and experts are recommended to counter politicized messages in the media and from governments. This is particularly true for large companies that have the capacity to do this. Messages about what businesses are doing for their employees and in their communities is also important. Some companies are helping schoolchildren from vulnerable families who can no longer get a school meal; others are providing public health messages about effective handwashing. Even CEOs can show they are working from home and self-isolating, while still being effective in their leadership. Following WHO advice, there is a need for the business community to move from general support to specific actions and focus on countries’ access to critical supplies, including a “Community Package of Critical Items” (a list of 46 items that all countries need). Of these items, 20 are either not available locally or available stocks are too limited. These missing items fall into four categories: Hygiene: Chlorine, HTH 70%, alcohol based hand rub, liquid soap; Diagnostics: lab screening tests, lab confirmation tests, enzymes, RNA extraction kits; PPE: gowns, scrubs, aprons, sterile gloves, protective goggles, face shields, masks (N95 or FFP2); Case management equipment: oxygen concentrators, oxygen delivery systems, mechanical ventilators. The call for action is for more money, to work with manufacturers to create capacity and to organize purchasing so there is guaranteed access, especially for poorer countries with less resilient public health systems. The concept is to create a global security stockpile of supplies and equipment, an effort that needs: Emergency financing Access to and increases in manufacturing capacity Access to national and supplier stockpiles Warehouses and distribution capacity')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_article_text(r'https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-2/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a1011",
   "metadata": {},
   "source": [
    "## Creating txt files out of extracted text content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72773bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in input_file.iterrows():\n",
    "    url_id = row['URL_ID']\n",
    "    url = row['URL']\n",
    "    \n",
    "    # Extract article text and title from the URL\n",
    "    title, article_text = extract_article_text(url)\n",
    "    \n",
    "    # Save the extracted title and text in a text file\n",
    "    #output_folder = r'D:\\DATA ANALYST PLAYGROUND\\Blackcoffer\\Extracted Text files'\n",
    "    with open(os.path.join(extracted_txt_folder_path, f'{url_id}.txt'), 'w', encoding='utf-8') as file:\n",
    "        file.write(f'{title}\\n\\n')\n",
    "        file.write(f' {article_text}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e65d9ed",
   "metadata": {},
   "source": [
    "## Functions to perform different text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f30b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_sentiment_analysis(text):\n",
    "   \n",
    "    full_text = text\n",
    "    # Cleaning using Stop Words Lists\n",
    "    #stop_words_folder = r'D:\\DATA ANALYST PLAYGROUND\\Blackcoffer\\StopWords'\n",
    "    stop_words = set()\n",
    "\n",
    "    for filename in os.listdir(stop_words_folder):\n",
    "        file_path = os.path.join(stop_words_folder, filename)\n",
    "        with open(file_path, 'rb') as file:\n",
    "            raw_data = file.read()\n",
    "            encoding_result = chardet.detect(raw_data)\n",
    "            encoding = encoding_result['encoding']\n",
    "\n",
    "        with open(file_path, 'r', encoding=encoding, errors='replace') as file:\n",
    "            stop_words.update(file.read().split())\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(full_text.lower())\n",
    "    cleaned_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "    print(\"Word count of the original article: \", len(tokens))\n",
    "    print(\"Word count of the cleaned article: \", len(cleaned_tokens))\n",
    "\n",
    "    # Creating a dictionary of Positive and Negative words\n",
    "    #positive_words = set(word for word in open(r'D:\\DATA ANALYST PLAYGROUND\\Blackcoffer\\MasterDictionary\\positive-words.txt').read().split() if word not in stop_words)\n",
    "    #negative_words = set(word for word in open(r'D:\\DATA ANALYST PLAYGROUND\\Blackcoffer\\MasterDictionary/negative-words.txt').read().split() if word not in stop_words)\n",
    "\n",
    "    # Extracting Derived variables\n",
    "    positive_score = sum(1 for word in cleaned_tokens if word in positive_words)\n",
    "    negative_score = sum(1 for word in cleaned_tokens if word in negative_words)\n",
    "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "    subjectivity_score = (positive_score + negative_score) / (len(cleaned_tokens) + 0.000001)\n",
    "\n",
    "    \n",
    "    # Return the results\n",
    "    return {\n",
    "        'POSITIVE SCORE': positive_score,\n",
    "        'NEGATIVE SCORE': negative_score,\n",
    "        'POLARITY SCORE': polarity_score,\n",
    "        'SUBJECTIVITY SCORE': subjectivity_score,\n",
    "    \n",
    "        # Add other variables as needed\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243052d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = r'https://insights.blackcoffer.com/rising-it-cities-and-its-impact-on-the-economy-environment-infrastructure-and-city-life-by-the-year-2040-2/'\n",
    "title, article_text = extract_article_text(url)\n",
    "sentiment_analysis_results = perform_sentiment_analysis(title, article_text)\n",
    "print(analysis_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc936c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Function to count syllables in a word\n",
    "    def count_syllables(word):\n",
    "        vowels = \"aeiou\"\n",
    "        count = 0\n",
    "\n",
    "        # Iterate through each letter in the word\n",
    "        for char in word:\n",
    "            # Count consecutive vowels\n",
    "            if char.lower() in vowels:\n",
    "                count += 1\n",
    "\n",
    "        # Exclude words ending with \"es\" and \"ed\" from syllable count\n",
    "        if word.lower().endswith(('es', 'ed')):\n",
    "            count -= 1\n",
    "\n",
    "        # Ensure a minimum count of 1\n",
    "        return max(count, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8289c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_readability_analysis(text):\n",
    "    \n",
    "    full_text = text\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(full_text.lower())\n",
    "\n",
    "    # let's calculate average sentence length\n",
    "    sentences = sent_tokenize(full_text)\n",
    "    avg_sentence_length = len(tokens) / len(sentences) if len(sentences) > 0 else 0\n",
    "\n",
    "    # Count syllables for each word\n",
    "    syllables_per_word = [count_syllables(word) for word in tokens]\n",
    "    #print(syllables_per_word)\n",
    "\n",
    "    # Calculate Percentage of Complex Words based on syllables\n",
    "    complex_words = [word for word, syllables in zip(tokens, syllables_per_word) if syllables > 2]\n",
    "    percentage_complex_words = (len(complex_words) / len(tokens)) * 100 if len(tokens) > 0 else 0\n",
    "    \n",
    "    # Calculate fog index\n",
    "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
    "\n",
    "\n",
    "   \n",
    "    return {\n",
    "        'AVG SENTENCE LENGTH': avg_sentence_length,\n",
    "        'PERCENTAGE OF COMPLEX WORDS': percentage_complex_words,\n",
    "        'FOG INDEX': fog_index\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "cd29edb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AVG SENTENCE LENGTH': 22.166666666666668, 'PERCENTAGE OF COMPLEX WORDS': 17.593984962406015, 'FOG INDEX': 15.904260651629073}\n"
     ]
    }
   ],
   "source": [
    "url = r'https://insights.blackcoffer.com/rising-it-cities-and-its-impact-on-the-economy-environment-infrastructure-and-city-life-by-the-year-2040-2/'\n",
    "title, article_text = extract_article_text(url)\n",
    "full_text = f\"{title} {article_text}\"\n",
    "\n",
    "readability_analysis_results = perform_readability_analysis(full_text)\n",
    "print(readability_analysis_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_basic_analysis(text):\n",
    "    \n",
    "    full_text = text\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(full_text.lower())\n",
    "    \n",
    "    #AVERAGE WORD PER SENTENCE\n",
    "    sentences = sent_tokenize(full_text)\n",
    "    avg_words_per_sentence = len(tokens)/len(sentences) if len(sentences) > 0 else 0\n",
    "    syllables_per_word = [count_syllables(word) for word in tokens]\n",
    "    complex_words = [word for word, syllables in zip(tokens, syllables_per_word) if syllables > 2]\n",
    "    complex_wordcount = len(complex_words)\n",
    "    \n",
    "    stop_words2 = set(stopwords.words('english'))\n",
    "    cleaned_tokens2 = [word for word in tokens if word.lower() not in stop_words2 and word not in string.punctuation]\n",
    "    word_count = len(cleaned_tokens2)\n",
    "    syllables_per_word = [count_syllables(word) for word in tokens]\n",
    "    average_syllable_count = sum(syllables_per_word) / len(syllables_per_word) if len(syllables_per_word) > 0 else 0\n",
    "    \n",
    "    # Define the list of personal pronouns\n",
    "    personal_pronouns = [\"I\", \"we\", \"my\", \"ours\", \"us\"]\n",
    "\n",
    "    # Use regex to find counts of personal pronouns\n",
    "    total_pronoun_count = sum(len(re.findall(r'\\b' + pronoun + r'\\b', full_text, flags=re.IGNORECASE)) for pronoun in personal_pronouns)\n",
    " \n",
    "    # Special care to exclude the country name \"US\"\n",
    "    total_pronoun_count -= len(re.findall(r'\\bUS\\b', full_text, flags=re.IGNORECASE))\n",
    "\n",
    "    \n",
    "    total_characters = sum(len(word) for word in tokens)\n",
    "\n",
    "    # Calculate the total number of words\n",
    "    total_words = len(tokens)\n",
    "\n",
    "    # Calculate the average word length\n",
    "    average_word_length = total_characters / total_words if total_words > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'AVERAGE WORD PER SENTENCE': avg_words_per_sentence,\n",
    "        'COMPLEX WORD COUNT': complex_wordcount,\n",
    "        'WORD COUNT': word_count,\n",
    "        'AVERAGE SYLLABLE COUNT':average_syllable_count,\n",
    "        'PRONOUN COUNT':total_pronoun_count,\n",
    "        'AVERAGE WORD LENGTH':average_word_length\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1f2d1323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AVERAGE WORD PER SENTENCE': 22.166666666666668, 'COMPLEX WORD COUNT': 234, 'WORD COUNT': 626, 'AVERAGE SYLLABLE COUNT': 1.700751879699248, 'PRONOUN COUNT': 11, 'AVERAGE WORD LENGTH': 4.327067669172933}\n"
     ]
    }
   ],
   "source": [
    "url = r'https://insights.blackcoffer.com/rising-it-cities-and-its-impact-on-the-economy-environment-infrastructure-and-city-life-by-the-year-2040-2/'\n",
    "title, article_text = extract_article_text(url)\n",
    "full_text = f\"{title} {article_text}\"\n",
    "\n",
    "basic_analysis_results = perform_basic_analysis(full_text)\n",
    "print(basic_analysis_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f34d3d3",
   "metadata": {},
   "source": [
    "## Writing the text analysis score on the output sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the \"Output Data Structure\" Excel sheet into a DataFrame\n",
    "#output_excel_path = r'D:\\DATA ANALYST PLAYGROUND\\Blackcoffer\\Output Data Structure.xlsx'\n",
    "df = pd.read_excel(output_excel_path)\n",
    "\n",
    "# Folder path containing your text files\n",
    "#extracted_txt_folder_path = r'D:\\DATA ANALYST PLAYGROUND\\Blackcoffer\\Extracted Text files'\n",
    "\n",
    "# Iterate through rows of the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Extract URL_ID and construct file path\n",
    "    url_id = row['URL_ID']\n",
    "    txt_file_path = os.path.join(extracted_txt_folder_path, f'{url_id}.txt')\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(txt_file_path):\n",
    "        # Read the text from the file\n",
    "        with open(txt_file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            \n",
    "        # Perform sentiment analysis\n",
    "        sentiment_analysis_results = perform_sentiment_analysis(text)\n",
    "        readability_analysis_results = perform_readability_analysis(text)\n",
    "        basic_analysis_results = perform_basic_analysis(text)\n",
    "\n",
    "        # Update the DataFrame with sentiment analysis results\n",
    "        df.at[index, 'POSITIVE SCORE'] = sentiment_analysis_results['POSITIVE SCORE']\n",
    "        df.at[index, 'NEGATIVE SCORE'] = sentiment_analysis_results['NEGATIVE SCORE']\n",
    "        df.at[index, 'POLARITY SCORE'] = sentiment_analysis_results['POLARITY SCORE']\n",
    "        df.at[index, 'SUBJECTIVITY SCORE'] = sentiment_analysis_results['SUBJECTIVITY SCORE']\n",
    "        df.at[index, 'AVG SENTENCE LENGTH'] = readability_analysis_results['AVG SENTENCE LENGTH']\n",
    "        df.at[index, 'PERCENTAGE OF COMPLEX WORDS'] = readability_analysis_results['PERCENTAGE OF COMPLEX WORDS']\n",
    "        df.at[index, 'FOG INDEX'] = readability_analysis_results['FOG INDEX']\n",
    "        df.at[index, 'AVG NUMBER OF WORDS PER SENTENCE'] = basic_analysis_results['AVERAGE WORD PER SENTENCE']\n",
    "        df.at[index, 'COMPLEX WORD COUNT'] = basic_analysis_results['COMPLEX WORD COUNT']\n",
    "        df.at[index, 'WORD COUNT'] = basic_analysis_results['WORD COUNT']\n",
    "        df.at[index, 'SYLLABLE PER WORD'] = basic_analysis_results['AVERAGE SYLLABLE COUNT']\n",
    "        df.at[index, 'PERSONAL PRONOUNS'] = basic_analysis_results['PRONOUN COUNT']\n",
    "        df.at[index, 'AVG WORD LENGTH'] = basic_analysis_results['AVERAGE WORD LENGTH']\n",
    "\n",
    "        # Add more columns as needed\n",
    "# Write the updated DataFrame back to the Excel sheet\n",
    "df.to_excel(output_excel_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f72e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99558021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6448af48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df44a61c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff363b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf4f108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707b6120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
